{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(label_path):\n",
    "    columns = ['class', 'x_center', 'y_center', 'width', 'height', 'confidence']\n",
    "    labels_df = pd.read_csv(label_path, sep=' ', names=columns)\n",
    "    return labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    x1_max, y1_max = max(box1[0], box2[0]), max(box1[1], box2[1])\n",
    "    x2_min, y2_min = min(box1[2], box2[2]), min(box1[3], box2[3])\n",
    "\n",
    "    inter_area = max(0, x2_min - x1_max) * max(0, y2_min - y1_max)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize bounding boxes\n",
    "def normalize_boxes(boxes, img_width, img_height):\n",
    "    normalized_boxes = []\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        x_center = (xmin + xmax) / 2 / img_width\n",
    "        y_center = (ymin + ymax) / 2 / img_height\n",
    "        width = (xmax - xmin) / img_width\n",
    "        height = (ymax - ymin) / img_height\n",
    "        normalized_boxes.append([x_center, y_center, width, height])\n",
    "    return normalized_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMS (keeping the higher-confidence box)\n",
    "def nms(visible_results, infrared_results, iou_threshold=0.5):\n",
    "    # Filter out empty dataframes\n",
    "    if visible_results.empty and infrared_results.empty:\n",
    "        return [], [], []\n",
    "    elif visible_results.empty:\n",
    "        combined_results = infrared_results\n",
    "    elif infrared_results.empty:\n",
    "        combined_results = visible_results\n",
    "    else:\n",
    "        combined_results = pd.concat([visible_results, infrared_results])\n",
    "    \n",
    "    # Sort by confidence in descending order\n",
    "    combined_results = combined_results.sort_values(by='confidence', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    final_boxes = []\n",
    "    final_scores = []\n",
    "    final_classes = []\n",
    "\n",
    "    for _, row in combined_results.iterrows():\n",
    "        box = [row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n",
    "        confidence = row['confidence']\n",
    "        cls = row['class']\n",
    "\n",
    "        if len(final_boxes) == 0:\n",
    "            final_boxes.append(box)\n",
    "            final_scores.append(confidence)\n",
    "            final_classes.append(cls)\n",
    "            continue\n",
    "\n",
    "        # Compute IoUs with existing boxes\n",
    "        ious = np.array([iou(box, b) for b in final_boxes])\n",
    "        \n",
    "        # Apply NMS\n",
    "        if np.max(ious) <= iou_threshold:\n",
    "            final_boxes.append(box)\n",
    "            final_scores.append(confidence)\n",
    "            final_classes.append(cls)\n",
    "        else:\n",
    "            # Retain the box with the higher confidence\n",
    "            max_iou_index = np.argmax(ious)\n",
    "            if confidence > final_scores[max_iou_index]:\n",
    "                final_boxes[max_iou_index] = box\n",
    "                final_scores[max_iou_index] = confidence\n",
    "                final_classes[max_iou_index] = cls\n",
    "\n",
    "    return final_boxes, final_scores, final_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the label folders\n",
    "visible_label_folder = 'C:/Users/letri/Documents/project/single_modality/yolov5/runs/val/iou45conf25/vis_best/labels/'\n",
    "infrared_label_folder = 'C:/Users/letri/Documents/project/single_modality/yolov5/runs/val/iou45conf25/ir_best/labels/'\n",
    "\n",
    "#visible_label_folder = '/Users/letriluan/Desktop/project/yolov5/runs/val/iou45conf25/vis_best/labels/'\n",
    "#infrared_label_folder = '/Users/letriluan/Desktop/project/yolov5/runs/val/iou45conf25/ir_best/labels/'\n",
    "\n",
    "labels_output_folder = 'C:/Users/letri/Documents/project/late_fusion_new/nms/epochbest/labels'\n",
    "images_output_folder = 'C:/Users/letri/Documents/project/late_fusion_new/nms/epochbest/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folders if they don't exist\n",
    "Path(labels_output_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(images_output_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing labels:  79%|███████▉  | 245/310 [00:13<00:02, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infrared label for 04107.txt not found, skipping...\n",
      "Infrared label for 04110.txt not found, skipping...\n",
      "Infrared label for 04111.txt not found, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing labels: 100%|██████████| 310/310 [00:17<00:00, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each pair of labels in the folders\n",
    "for visible_label_name in tqdm(os.listdir(visible_label_folder), desc=\"Processing labels\"):\n",
    "    visible_label_path = os.path.join(visible_label_folder, visible_label_name)\n",
    "    infrared_label_path = os.path.join(infrared_label_folder, visible_label_name)\n",
    "\n",
    "    if not os.path.exists(infrared_label_path):\n",
    "        print(f\"Infrared label for {visible_label_name} not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    visible_results_df = read_labels(visible_label_path)\n",
    "    infrared_results_df = read_labels(infrared_label_path)\n",
    "    visible_image_path = os.path.join('C:/Users/letri/Documents/project/single_modality/data/Vis/images/test', visible_label_name.replace('.txt', '.png'))\n",
    "    image = cv2.imread(visible_image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    img_height, img_width = image.shape[0], image.shape[1]  \n",
    "\n",
    "    visible_results_df['xmin'] = (visible_results_df['x_center'] - visible_results_df['width'] / 2) * img_width\n",
    "    visible_results_df['ymin'] = (visible_results_df['y_center'] - visible_results_df['height'] / 2) * img_height\n",
    "    visible_results_df['xmax'] = (visible_results_df['x_center'] + visible_results_df['width'] / 2) * img_width\n",
    "    visible_results_df['ymax'] = (visible_results_df['y_center'] + visible_results_df['height'] / 2) * img_height\n",
    "\n",
    "    infrared_results_df['xmin'] = (infrared_results_df['x_center'] - infrared_results_df['width'] / 2) * img_width\n",
    "    infrared_results_df['ymin'] = (infrared_results_df['y_center'] - infrared_results_df['height'] / 2) * img_height\n",
    "    infrared_results_df['xmax'] = (infrared_results_df['x_center'] + infrared_results_df['width'] / 2) * img_width\n",
    "    infrared_results_df['ymax'] = (infrared_results_df['y_center'] + infrared_results_df['height'] / 2) * img_height\n",
    "\n",
    "    # Fuse the results using ProEnD\n",
    "    fused_boxes, fused_scores, fused_classes = nms(visible_results_df, infrared_results_df)\n",
    "    normalized_boxes = normalize_boxes(fused_boxes, img_width, img_height)\n",
    "    combined_results = sorted(zip(normalized_boxes, fused_scores, fused_classes), key=lambda x: x[0][0])\n",
    "\n",
    "    prediction_file_path = os.path.join(labels_output_folder, visible_label_name)\n",
    "    with open(prediction_file_path, 'w') as f:\n",
    "        for box, score, cls in combined_results:\n",
    "            f.write(f'{cls} {box[0]} {box[1]} {box[2]} {box[3]} {score}\\n')\n",
    "\n",
    "    \n",
    "    for box, confidence, cls in zip(fused_boxes, fused_scores, fused_classes):\n",
    "        xmin, ymin, xmax, ymax = map(int, box)\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        label_text = f'{cls} {confidence:.2f}'\n",
    "        cv2.putText(image, label_text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Save the result image\n",
    "    output_image_path = os.path.join(images_output_folder, visible_label_name.replace('.txt', '.png'))\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            split_values = re.split(r'\\s+|,', line.strip())\n",
    "            try:\n",
    "                data.append([float(x) for x in split_values])\n",
    "            except ValueError:\n",
    "                print(f\"Warning: Could not convert line to float values - '{line.strip()}'\")\n",
    "    return np.array(data)\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    xi1 = max(x1 - w1 / 2, x2 - w2 / 2)\n",
    "    yi1 = max(y1 - h1 / 2, y2 - h2 / 2)\n",
    "    xi2 = min(x1 + w1 / 2, x2 + w2 / 2)\n",
    "    yi2 = min(y1 + h1 / 2, y2 + h2 / 2)\n",
    "    \n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / (union_area + 1e-16)\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
    "\n",
    "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "\n",
    "    x = np.linspace(0, 1, 101)\n",
    "    ap = np.trapz(np.interp(x, mrec, mpre), x)\n",
    "    \n",
    "    return ap, mpre, mrec\n",
    "\n",
    "def smooth(y, f=0.05):\n",
    "    nf = round(len(y) * f * 2) // 2 + 1\n",
    "    p = np.ones(nf // 2)\n",
    "    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)\n",
    "    return np.convolve(yp, np.ones(nf) / nf, mode=\"valid\")\n",
    "\n",
    "def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir=\".\", names=(), eps=1e-16, prefix=\"\"):\n",
    "    i = np.argsort(-conf)\n",
    "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
    "    \n",
    "    unique_classes, nt = np.unique(target_cls, return_counts=True)\n",
    "    nc = unique_classes.shape[0]\n",
    "    px, py = np.linspace(0, 1, 1000), []\n",
    "    ap, p, r = np.zeros((nc, tp.shape[1])), np.zeros((nc, 1000)), np.zeros((nc, 1000))\n",
    "    \n",
    "    for ci, c in enumerate(unique_classes):\n",
    "        i = pred_cls == c\n",
    "        n_l = nt[ci]\n",
    "        n_p = i.sum()\n",
    "        if n_p == 0 or n_l == 0:\n",
    "            continue\n",
    "        fpc = (1 - tp[i]).cumsum(0)\n",
    "        tpc = tp[i].cumsum(0)\n",
    "        recall = tpc / (n_l + eps)\n",
    "        r[ci] = np.interp(-px, -conf[i], recall[:, 0], left=0)\n",
    "        precision = tpc / (tpc + fpc)\n",
    "        p[ci] = np.interp(-px, -conf[i], precision[:, 0], left=1)\n",
    "        for j in range(tp.shape[1]):\n",
    "            ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])\n",
    "            if plot and j == 0:\n",
    "                py.append(np.interp(px, mrec, mpre))\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + eps)\n",
    "\n",
    "    i = smooth(f1.mean(0), 0.1).argmax()\n",
    "    p, r, f1 = p[:, i], r[:, i], f1[:, i]\n",
    "    tp = (r * nt).round()\n",
    "    fp = (tp / (p + eps) - tp).round()\n",
    "    return tp, fp, p, r, f1, ap, unique_classes.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: [571. 655.]\n",
      "False Positives: [30. 93.]\n",
      "Precision: [0.95049571 0.87515192]\n",
      "Recall: [0.72461929 0.95620438]\n",
      "F1 Score: [0.82232865 0.91388453]\n",
      "Average Precision (AP): [[0.85727117]\n",
      " [0.97154696]]\n",
      "Overall mAP: 0.91440906434008\n"
     ]
    }
   ],
   "source": [
    "true_dir = 'C:/Users/letri/Documents/project/single_modality/data/Vis/labels/test'\n",
    "predict_dir = 'C:/Users/letri/Documents/project/late_fusion_new/nms/epochbest/labels'\n",
    "\n",
    "# List files in directories\n",
    "true_files = set(os.listdir(true_dir))\n",
    "predict_files = set(os.listdir(predict_dir))\n",
    "\n",
    "# Find common files in both directories\n",
    "common_files = true_files.intersection(predict_files)\n",
    "\n",
    "iou_threshold = 0.5\n",
    "tp_list = []\n",
    "conf_list = []\n",
    "pred_cls_list = []\n",
    "target_cls_list = []\n",
    "\n",
    "for file_name in true_files:\n",
    "    ground_truths = load_data(os.path.join(true_dir, file_name))\n",
    "    predictions = load_data(os.path.join(predict_dir, file_name)) if file_name in predict_files else []\n",
    "\n",
    "    tp = []\n",
    "    conf = []\n",
    "    pred_cls = []\n",
    "    target_cls = []\n",
    "    matched_gt = set()\n",
    "\n",
    "    for pred in predictions:\n",
    "        pred_class = pred[0]\n",
    "        pred_box = pred[1:5]\n",
    "        pred_conf = pred[5]\n",
    "\n",
    "        best_iou = 0\n",
    "        best_gt_index = -1\n",
    "\n",
    "        for gt_index, gt in enumerate(ground_truths):\n",
    "            gt_class = gt[0]\n",
    "            gt_box = gt[1:5]\n",
    "\n",
    "            if pred_class == gt_class:\n",
    "                iou = compute_iou(pred_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_index = gt_index\n",
    "\n",
    "        if best_iou > iou_threshold and best_gt_index not in matched_gt:\n",
    "            tp.append(1)\n",
    "            matched_gt.add(best_gt_index)\n",
    "        else:\n",
    "            tp.append(0)\n",
    "\n",
    "        conf.append(pred_conf)\n",
    "        pred_cls.append(pred_class)\n",
    "\n",
    "    # Append unmatched ground truths as false negatives\n",
    "    for gt in ground_truths:\n",
    "        target_cls.append(gt[0])\n",
    "\n",
    "    tp_list.extend(tp)\n",
    "    conf_list.extend(conf)\n",
    "    pred_cls_list.extend(pred_cls)\n",
    "    target_cls_list.extend(target_cls)\n",
    "\n",
    "tp = np.array(tp_list).reshape(-1, 1)\n",
    "conf = np.array(conf_list)\n",
    "pred_cls = np.array(pred_cls_list)\n",
    "target_cls = np.array(target_cls_list)\n",
    "\n",
    "tp, fp, p, r, f1, ap, unique_classes = ap_per_class(tp, conf, pred_cls, target_cls)\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Average Precision (AP): {ap}\")\n",
    "print(f\"Overall mAP: {ap.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
